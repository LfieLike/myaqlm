{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quant/.conda/envs/AWQ/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/tmp/ipykernel_972400/2310833656.py:96: UserWarning: index_reduce() is in beta and the API may change at any time. (Triggered internally at ../aten/src/ATen/native/cuda/Indexing.cu:1193.)\n",
      "  clusters[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([262144, 4])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "import time\n",
    "import random\n",
    "from tqdm.auto import trange\n",
    "# import ipynbname  # pip install ipynbname\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import transformers\n",
    "\n",
    "from typing import Optional,Union,List\n",
    "\n",
    "torch.backends.cudnn.allow_tf32 = False\n",
    "torch.backends.cuda.matmul.allow_tf32 = False\n",
    "def find_nearest_cluster(data, clusters, block_size_vals: int = 2**30, devices: Optional[List[torch.device]] = None):\n",
    "    \"\"\"Find nearest clusters for each batch of data and return their indices\"\"\"\n",
    "    if devices is None:\n",
    "        devices = [data.device]\n",
    "    block_size = block_size_vals // len(clusters)\n",
    "    shard_size = (len(data) - 1) // len(devices) + 1\n",
    "    data = [\n",
    "        data[gi * shard_size : (gi + 1) * shard_size].to(devices[gi], non_blocking=True) for gi in range(len(devices))\n",
    "    ]\n",
    "    nearest_indices = [torch.empty(len(data[gi]), dtype=torch.int64, device=devices[gi]) for gi in range(len(devices))]\n",
    "    clusters = [clusters.to(device, non_blocking=True) for device in devices]\n",
    "\n",
    "    for block_start in range(0, shard_size, block_size):\n",
    "        for gi in range(len(devices)):\n",
    "            nearest_indices[gi][block_start : block_start + block_size] = torch.addmm(\n",
    "                torch.bmm(clusters[gi][:, None, :], clusters[gi][:, :, None]).flatten(),\n",
    "                data[gi][block_start : block_start + block_size],\n",
    "                clusters[gi].T,\n",
    "                beta=-0.5,\n",
    "            ).argmax(1)\n",
    "    clusters = clusters[0]\n",
    "    nearest_indices = torch.cat([nearest_indices[gi].to(devices[0]) for gi in range(len(devices))], dim=0)\n",
    "    reconstructed_data = clusters[nearest_indices]\n",
    "    return nearest_indices, reconstructed_data\n",
    "def fit_kmeans(\n",
    "    data: torch.Tensor,\n",
    "    k: int,\n",
    "    max_iter: int = 1000,\n",
    "    check_every: int = 10,\n",
    "    rtol: float = 1e-06,\n",
    "    atol: float = 1e-08,\n",
    "    greedy_init: bool = False,\n",
    "    block_size_vals: int = 2**30,\n",
    "    devices: Optional[List[torch.device]] = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    :param data: [nsamples, dim]\n",
    "    :param k: number of centroids\n",
    "    :param max_iter: run at most this many iterations\n",
    "    :param check_every: check for convergence (allclose(new_centroids, old_centroids)) once in this many steps\n",
    "    :param rtol: early stopping relative tolerance for centroids\n",
    "    :param atol: early stopping absolute tolerance for centroids\n",
    "    :param greedy_init: if True, init by greedily selecting the point that is farthest from any cluster\n",
    "        if False (default), initialize with random points using pytorch global RNG\n",
    "    :param block_size_vals: how many dot products to compute at a time\n",
    "    :param devices: if specified, run kmeans in data-parallel mode across these devices\n",
    "    :return: (clusters float[k, dim], data_indices int[nsamples], reconstructed_data: float[nsamples, dim])\n",
    "    \"\"\"\n",
    "    if devices is None:\n",
    "        devices = [data.device]\n",
    "\n",
    "    if greedy_init:\n",
    "        clusters = _kmeans_greedy_init(data, k)\n",
    "    else:\n",
    "        clusters = data[torch.randperm(data.shape[0])[:k], :]  # [k, dim]\n",
    "\n",
    "    block_size = block_size_vals // k\n",
    "    shard_size = (len(data) - 1) // len(devices) + 1\n",
    "    data = [\n",
    "        data[gi * shard_size : (gi + 1) * shard_size].to(devices[gi], non_blocking=True) for gi in range(len(devices))\n",
    "    ]\n",
    "    nearest_indices = [torch.empty(len(data[gi]), dtype=torch.int64, device=devices[gi]) for gi in range(len(devices))]\n",
    "    clusters = [clusters.to(device, non_blocking=True) for device in devices]\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        for block_start in range(0, shard_size, block_size):\n",
    "            for gi in range(len(devices)):\n",
    "                nearest_indices[gi][block_start : block_start + block_size] = torch.addmm(\n",
    "                    torch.bmm(clusters[gi][:, None, :], clusters[gi][:, :, None]).flatten(),\n",
    "                    data[gi][block_start : block_start + block_size],\n",
    "                    clusters[gi].T,\n",
    "                    beta=-0.5,\n",
    "                ).argmax(1)\n",
    "            # note: the above formula equals to - 0.5 || data[:, None, :] - clusters[None, :, :] || ^ 2 + const\n",
    "\n",
    "        if len(devices) == 1:\n",
    "            new_clusters = [\n",
    "                clusters[0]\n",
    "                .clone()\n",
    "                .index_reduce_(dim=0, index=nearest_indices[0], source=data[0], reduce=\"mean\", include_self=False)\n",
    "            ]\n",
    "        else:\n",
    "            cluster_sums = [\n",
    "                torch.zeros_like(clusters[gi])\n",
    "                .index_add(dim=0, index=nearest_indices[gi], source=data[gi])\n",
    "                .to(devices[0], non_blocking=True)\n",
    "                for gi in range(len(devices))\n",
    "            ]\n",
    "            cluster_counts = [\n",
    "                torch.bincount(nearest_indices[gi], minlength=k).to(devices[0], non_blocking=True)\n",
    "                for gi in range(len(devices))\n",
    "            ]\n",
    "            for gi in range(1, len(devices)):\n",
    "                cluster_sums[0] += cluster_sums[gi]\n",
    "                cluster_counts[0] += cluster_counts[gi]\n",
    "\n",
    "            new_clusters = [cluster_sums[0] / cluster_counts[0].unsqueeze(1).clamp_min(1)]\n",
    "            new_clusters[0] += (cluster_counts[0].unsqueeze(1) == 0) * clusters[0]\n",
    "            for gi in range(1, len(devices)):\n",
    "                new_clusters.append(new_clusters[0].to(devices[gi], non_blocking=True))\n",
    "\n",
    "        if i % check_every == 0:\n",
    "            if torch.allclose(new_clusters[0], clusters[0], rtol=rtol, atol=atol):\n",
    "                break\n",
    "        clusters = new_clusters\n",
    "    for block_start in range(0, shard_size, block_size):\n",
    "        for gi in range(len(devices)):\n",
    "            nearest_indices[gi][block_start : block_start + block_size] = torch.addmm(\n",
    "                torch.bmm(clusters[gi][:, None, :], clusters[gi][:, :, None]).flatten(),\n",
    "                data[gi][block_start : block_start + block_size],\n",
    "                clusters[gi].T,\n",
    "                beta=-0.5,\n",
    "            ).argmax(1)\n",
    "\n",
    "    clusters = clusters[0]\n",
    "    nearest_indices = torch.cat([nearest_indices[gi].to(devices[0]) for gi in range(len(devices))], dim=0)\n",
    "    reconstructed_data = clusters[nearest_indices]\n",
    "    return clusters, nearest_indices, reconstructed_data\n",
    "x = torch.randn(4096*4096//16//4, 4, device='cuda')\n",
    "clusters, nearest_indices, reconstructed_data = fit_kmeans(x,256,1000)\n",
    "reconstructed_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0') \n",
    "x = torch.load(\"/home/quant/test.pth\",map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 码本量化过程\n",
    "# 1. 按列进行除以scale\n",
    "# 2. 按列切分，因为权重矩阵是转置后的\n",
    "# 3. kmeans初始化\n",
    "org_weight = x\n",
    "codebook_num_bits = 4\n",
    "codebook_num = 2**(codebook_num_bits)\n",
    "centroids_num = 256\n",
    "# 计算每一行的二范数\n",
    "scales = org_weight.norm(p=2, dim=1, keepdim=True)\n",
    "# nn.Parameter(scales, requires_grad=True)\n",
    "# 每一行除以其对应的范数\n",
    "normalized_tensor = org_weight / scales\n",
    "weight_list = org_weight.split(org_weight.shape[0]//codebook_num,dim = 0)\n",
    "clusters_list = []\n",
    "nearest_indices_list = []\n",
    "reconstructed_data_list = []\n",
    "for weight in weight_list:\n",
    "    clusters, nearest_indices, reconstructed_data=fit_kmeans(weight.view(-1,4),k = centroids_num)\n",
    "    clusters_list.append(clusters.unsqueeze(0))\n",
    "    nearest_indices_list.append(nearest_indices.unsqueeze(0))\n",
    "    reconstructed_data_list.append(reconstructed_data.view(weight.shape))\n",
    "clusters_merge = torch.cat(clusters_list,dim = 0)\n",
    "nearest_indices_merge = torch.cat(nearest_indices_list,dim = 0)\n",
    "reconstructed_data_merge = torch.cat(reconstructed_data_list,dim = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4096, 4096])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstructed_data_merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "weight has to be a 2D Tensor, but got Tensor of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/quant/AQLM-main/notebooks/kmeans.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.242.193/home/quant/AQLM-main/notebooks/kmeans.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m offsets \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mLongTensor([\u001b[39m0\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.242.193/home/quant/AQLM-main/notebooks/kmeans.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# 通过EmbeddingBag获取嵌入结果\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B192.168.242.193/home/quant/AQLM-main/notebooks/kmeans.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m output \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49membedding_bag(offsets,\u001b[39minput\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.242.193/home/quant/AQLM-main/notebooks/kmeans.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mprint\u001b[39m(output) \n",
      "File \u001b[0;32m~/.conda/envs/AWQ/lib/python3.10/site-packages/torch/nn/functional.py:2362\u001b[0m, in \u001b[0;36membedding_bag\u001b[0;34m(input, weight, offsets, max_norm, norm_type, scale_grad_by_freq, mode, sparse, per_sample_weights, include_last_offset, padding_idx)\u001b[0m\n\u001b[1;32m   2356\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2357\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39membedding_bag: If per_sample_weights (\u001b[39m\u001b[39m{\u001b[39;00mper_sample_weights\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m) is not None, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2358\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mthen it must have the same shape as the input (\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39minput\u001b[39m\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2359\u001b[0m     )\n\u001b[1;32m   2361\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m weight\u001b[39m.\u001b[39mdim() \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m-> 2362\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2363\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mweight has to be a 2D Tensor, but got Tensor of dimension \u001b[39m\u001b[39m{\u001b[39;00mweight\u001b[39m.\u001b[39mdim()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2364\u001b[0m     )\n\u001b[1;32m   2366\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim() \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m   2367\u001b[0m     \u001b[39mif\u001b[39;00m offsets \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: weight has to be a 2D Tensor, but got Tensor of dimension 1"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# 假设我们有一个词汇表大小为10，嵌入维度为3\n",
    "embedding_dim = 3\n",
    "num_embeddings = 10\n",
    "\n",
    "# 创建EmbeddingBag对象\n",
    "embedding_bag = nn.EmbeddingBag(num_embeddings, embedding_dim, mode='mean')\n",
    "\n",
    "# 一个示例输入，假设0, 1, 2是词汇表中的索引\n",
    "input = torch.LongTensor([1, 2, 3, 4, 5])\n",
    "\n",
    "# offsets用于告诉EmbeddingBag每个“bag”（即句子或文档）的起始位置\n",
    "# 在这个例子中，我们只有一个bag，它从索引0开始\n",
    "offsets = torch.LongTensor([0])\n",
    "offsets = torch.arange(0, codes.size(0), dtype=torch.long)\n",
    "# 通过EmbeddingBag获取嵌入结果\n",
    "output = F.embedding_bag(offsets,input)\n",
    "\n",
    "print(output) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9365,  1.9752,  1.7521, -0.4886, -0.7203],\n",
      "        [ 0.6167,  0.8720,  1.4587,  0.0234,  0.4352],\n",
      "        [-0.1475,  0.0564, -0.3602,  0.8113,  0.5882],\n",
      "        [ 0.1575, -1.2660,  1.6896, -0.3704, -0.1198],\n",
      "        [-1.0532,  0.2494,  0.5768, -0.1848, -0.2209],\n",
      "        [ 0.7181,  0.0438, -0.7713,  0.2479, -0.6923],\n",
      "        [-1.6777, -1.3979,  0.4613, -0.1491, -0.4602],\n",
      "        [ 0.9126, -0.0039, -1.0053,  0.0780,  1.3526],\n",
      "        [-0.3347, -0.5506,  0.4579, -0.0217, -0.9277],\n",
      "        [ 0.5397,  0.9202,  0.6600,  0.8914, -0.2042]])\n",
      "tensor([[-0.1475,  0.0564, -0.3602,  0.8113,  0.5882],\n",
      "        [ 0.6167,  0.8720,  1.4587,  0.0234,  0.4352],\n",
      "        [-0.1475,  0.0564, -0.3602,  0.8113,  0.5882]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "num_embeddings = 10\n",
    "embedding_dim =  5\n",
    "embedding_matrix = torch.randn(num_embeddings, embedding_dim)\n",
    "input_ids = torch.LongTensor([2, 1, 2])  # 示例输入\n",
    "offsets = torch.LongTensor([0, 1,2])  # 每个序列的开始位置\n",
    "output = F.embedding_bag(input_ids, embedding_matrix,offsets, mode='sum')\n",
    "print(embedding_matrix)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.6272, 0.2958],\n",
      "         [0.2129, 0.6498]],\n",
      "\n",
      "        [[0.5710, 0.5451],\n",
      "         [0.1002, 0.7316]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.6272, 0.2958],\n",
       "        [0.2129, 0.6498],\n",
       "        [0.5710, 0.5451],\n",
       "        [0.1002, 0.7316]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix = torch.rand((2,2,2))\n",
    "print(embedding_matrix)\n",
    "embedding_matrix.flatten(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import math\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "from tqdm.auto import trange\n",
    "# import ipynbname  # pip install ipynbname\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import transformers\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "\n",
    "from typing import Optional,Union,List\n",
    "def fit_kmeans(\n",
    "    data: torch.Tensor,\n",
    "    k: int,\n",
    "    max_iter: int = 100,\n",
    "    check_every: int = 10,\n",
    "    rtol: float = 1e-06,\n",
    "    atol: float = 1e-08,\n",
    "    greedy_init: bool = False,\n",
    "    block_size_vals: int = 2**30,\n",
    "    devices: Optional[List[torch.device]] = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    :param data: [nsamples, dim]\n",
    "    :param k: number of centroids\n",
    "    :param max_iter: run at most this many iterations\n",
    "    :param check_every: check for convergence (allclose(new_centroids, old_centroids)) once in this many steps\n",
    "    :param rtol: early stopping relative tolerance for centroids\n",
    "    :param atol: early stopping absolute tolerance for centroids\n",
    "    :param greedy_init: if True, init by greedily selecting the point that is farthest from any cluster\n",
    "        if False (default), initialize with random points using pytorch global RNG\n",
    "    :param block_size_vals: how many dot products to compute at a time\n",
    "    :param devices: if specified, run kmeans in data-parallel mode across these devices\n",
    "    :return: (clusters float[k, dim], data_indices int[nsamples], reconstructed_data: float[nsamples, dim])\n",
    "    \"\"\"\n",
    "    if devices is None:\n",
    "        devices = [data.device]\n",
    "\n",
    "    if greedy_init:\n",
    "        clusters = _kmeans_greedy_init(data, k)\n",
    "    else:\n",
    "        clusters = data[torch.randperm(data.shape[0])[:k], :]  # [k, dim]\n",
    "\n",
    "    block_size = block_size_vals // k\n",
    "    shard_size = (len(data) - 1) // len(devices) + 1\n",
    "    data = [\n",
    "        data[gi * shard_size : (gi + 1) * shard_size].to(devices[gi], non_blocking=True) for gi in range(len(devices))\n",
    "    ]\n",
    "    nearest_indices = [torch.empty(len(data[gi]), dtype=torch.int64, device=devices[gi]) for gi in range(len(devices))]\n",
    "    clusters = [clusters.to(device, non_blocking=True) for device in devices]\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        for block_start in range(0, shard_size, block_size):\n",
    "            for gi in range(len(devices)):\n",
    "                nearest_indices[gi][block_start : block_start + block_size] = torch.addmm(\n",
    "                    torch.bmm(clusters[gi][:, None, :], clusters[gi][:, :, None]).flatten(),\n",
    "                    data[gi][block_start : block_start + block_size],\n",
    "                    clusters[gi].T,\n",
    "                    beta=-0.5,\n",
    "                ).argmax(1)\n",
    "            # note: the above formula equals to - 0.5 || data[:, None, :] - clusters[None, :, :] || ^ 2 + const\n",
    "\n",
    "        if len(devices) == 1:\n",
    "            new_clusters = [\n",
    "                clusters[0]\n",
    "                .clone()\n",
    "                .index_reduce_(dim=0, index=nearest_indices[0], source=data[0], reduce=\"mean\", include_self=False)\n",
    "            ]\n",
    "        else:\n",
    "            cluster_sums = [\n",
    "                torch.zeros_like(clusters[gi])\n",
    "                .index_add(dim=0, index=nearest_indices[gi], source=data[gi])\n",
    "                .to(devices[0], non_blocking=True)\n",
    "                for gi in range(len(devices))\n",
    "            ]\n",
    "            cluster_counts = [\n",
    "                torch.bincount(nearest_indices[gi], minlength=k).to(devices[0], non_blocking=True)\n",
    "                for gi in range(len(devices))\n",
    "            ]\n",
    "            for gi in range(1, len(devices)):\n",
    "                cluster_sums[0] += cluster_sums[gi]\n",
    "                cluster_counts[0] += cluster_counts[gi]\n",
    "\n",
    "            new_clusters = [cluster_sums[0] / cluster_counts[0].unsqueeze(1).clamp_min(1)]\n",
    "            new_clusters[0] += (cluster_counts[0].unsqueeze(1) == 0) * clusters[0]\n",
    "            for gi in range(1, len(devices)):\n",
    "                new_clusters.append(new_clusters[0].to(devices[gi], non_blocking=True))\n",
    "\n",
    "        if i % check_every == 0:\n",
    "            if torch.allclose(new_clusters[0], clusters[0], rtol=rtol, atol=atol):\n",
    "                break\n",
    "        clusters = new_clusters\n",
    "    for block_start in range(0, shard_size, block_size):\n",
    "        for gi in range(len(devices)):\n",
    "            nearest_indices[gi][block_start : block_start + block_size] = torch.addmm(\n",
    "                torch.bmm(clusters[gi][:, None, :], clusters[gi][:, :, None]).flatten(),\n",
    "                data[gi][block_start : block_start + block_size],\n",
    "                clusters[gi].T,\n",
    "                beta=-0.5,\n",
    "            ).argmax(1)\n",
    "\n",
    "    clusters = clusters[0]\n",
    "    nearest_indices = torch.cat([nearest_indices[gi].to(devices[0]) for gi in range(len(devices))], dim=0)\n",
    "    reconstructed_data = clusters[nearest_indices]\n",
    "    return clusters, nearest_indices, reconstructed_data\n",
    "\n",
    "def get_nearest_indices(\n",
    "    S: torch.Tensor, #重要性\n",
    "    W,\n",
    "    shape, # 权重的原始形状\n",
    "    centroids,\n",
    "    devices: Optional[List[torch.device]] = None,\n",
    "):\n",
    "    if S is None:\n",
    "        S = torch.zeros(shape[0]).to(W.device)\n",
    "        S[0] = 1\n",
    "        # S[0] = 1\n",
    "    # if devices is None:\n",
    "    #     devices = [data.device]\n",
    "    # W  N*D\n",
    "    # centroids n_centroids*D\n",
    "    a1 = W.view(-1,centroids.shape[-1]).unsqueeze(1)\n",
    "    # S为每一行的重要性权重，将其扩展成矩阵形式，方便计算\n",
    "    s1 = S.repeat_interleave(shape[1]).view(a1.shape)\n",
    "    b1 = centroids.unsqueeze(0)\n",
    "    print(a1.shape)\n",
    "    print(b1.shape)\n",
    "    print(s1.shape)\n",
    "    dist = ((a1-b1)**2*s1).sum(-1)\n",
    "\n",
    "    # assignments = []\n",
    "    assignments = dist.argmin(-1)\n",
    "    return assignments\n",
    "def quantize(org_weight,codebook_num = 2,centroids_num = 256,block_size = 64,centroid_len = 8):\n",
    "    # 计算每一行的二范数\n",
    "    # max_matrix = get_max(org_weight)\n",
    "    reshspe_weight = org_weight.view(-1,block_size)\n",
    "    scales = reshspe_weight.norm(p=2, dim=1, keepdim=True).float()\n",
    "    # nn.Parameter(scales, requires_grad=True)\n",
    "    # 每一行除以其对应的范数\n",
    "    normalized_tensor = (reshspe_weight / scales)\n",
    "    weight_list = normalized_tensor.split(normalized_tensor.shape[0]//codebook_num,dim = 0)\n",
    "    print(len(weight_list))\n",
    "    clusters_list = []\n",
    "    nearest_indices_list = []\n",
    "    reconstructed_data_list = []\n",
    "    for weight in weight_list:\n",
    "        clusters, nearest_indices, reconstructed_data=fit_kmeans(weight.view(-1,centroid_len),k = centroids_num,max_iter= 100)\n",
    "        clusters_list.append(clusters.unsqueeze(0))\n",
    "        nearest_indices_list.append(nearest_indices.unsqueeze(0))\n",
    "        reconstructed_data_list.append(reconstructed_data.view(weight.shape))\n",
    "        print(nearest_indices.max())\n",
    "    clusters_merge = torch.cat(clusters_list,dim = 0)\n",
    "    nearest_indices_merge = torch.cat(nearest_indices_list,dim = 0)\n",
    "    reconstructed_data_merge = (torch.cat(reconstructed_data_list,dim = 0)*scales)\n",
    "    reconstructed_data_merge = reconstructed_data_merge.view(org_weight.shape)\n",
    "    print(reconstructed_data_merge.max())\n",
    "    return clusters_merge,nearest_indices_merge,reconstructed_data_merge,scales\n",
    "def col_wise_class(org_weight,class_num,max_iter = 100):\n",
    "    clusters, nearest_indices, reconstructed_data=fit_kmeans(org_weight,k = class_num,max_iter= 500)\n",
    "    return nearest_indices\n",
    "class Quantization(nn.Module):\n",
    "    \n",
    "    def __init__(self,layer,codebook_num = 2,centroids_num = 256,bolck_size = 128,centroid_len = 4) -> None:\n",
    "        super().__init__()\n",
    "        self.layer = layer.float()\n",
    "        self.dev = self.layer.weight.device \n",
    "        W = self.layer.weight.data.clone().cuda()\n",
    "        self.rows = W.shape[0]\n",
    "        self.columns = W.shape[1]\n",
    "        self.H = torch.zeros((self.columns, self.columns), device=self.dev,dtype= torch.float64)\n",
    "        self.nsamples = 0\n",
    "        self.codebook_num = codebook_num\n",
    "        self.centroids_num = centroids_num\n",
    "        self.centroid_len = centroid_len\n",
    "        clusters_merge,nearest_indices_merge,reconstructed_data_merge,scales \\\n",
    "            = quantize(W.float(),codebook_num=codebook_num,block_size=bolck_size,centroid_len=centroid_len)\n",
    "        self.codebooks = nn.Parameter(clusters_merge,requires_grad=True)\n",
    "        self.scales = nn.Parameter(scales,requires_grad=True)\n",
    "        self.scaler_row = torch.zeros((self.columns), device=self.dev)\n",
    "        self.codes = nn.Parameter(nearest_indices_merge,requires_grad=False)\n",
    "        self.reconstructed_data_merge = reconstructed_data_merge.to(self.dev)\n",
    "        self.bolck_size=bolck_size\n",
    "    def add_batch(self, inp, out):\n",
    "        if len(inp.shape) == 2:\n",
    "            inp = inp.unsqueeze(0)\n",
    "        tmp = inp.shape[0]\n",
    "        if isinstance(self.layer, nn.Linear) or isinstance(self.layer, transformers.Conv1D):\n",
    "            if len(inp.shape) == 3:\n",
    "                inp = inp.reshape((-1, inp.shape[-1]))\n",
    "            inp = inp.t()\n",
    "        self.H *= self.nsamples / (self.nsamples + tmp)\n",
    "        self.nsamples += tmp\n",
    "        self.scaler_row *= self.nsamples / (self.nsamples+tmp)\n",
    "        inp = inp.type(torch.float32)\n",
    "        self.scaler_row += torch.norm(inp, p=2, dim=1) ** 2  / self.nsamples\n",
    "        inp = math.sqrt(2 / self.nsamples) * inp.float()\n",
    "        self.H += inp.matmul(inp.t())\n",
    "        \n",
    "    def differentiable_dequantize(self):\n",
    "        codebook_num = self.codebook_num\n",
    "        codes = self.codes.clone()\n",
    "        for i in range(codebook_num):\n",
    "            codes[i,:]+=self.centroids_num*i\n",
    "        codebook_offsets = torch.arange(0,self.layer.weight.data.numel()//self.centroid_len).to(self.dev)\n",
    "        reconstruct_weight = F.embedding_bag(codes.flatten(),self.codebooks.flatten(0,1),codebook_offsets,mode=\"sum\")\n",
    "        return (reconstruct_weight.view(-1,self.bolck_size)*self.scales).view((self.rows, self.columns))\n",
    "    def update_index(self):\n",
    "        reshspe_weight = self.layer.weight.data.clone().cuda().view(-1,self.bolck_size)\n",
    "        # scales = reshspe_weight.norm(p=2, dim=1, keepdim=True).float()\n",
    "        # nn.Parameter(scales, requires_grad=True)\n",
    "        # 每一行除以其对应的范数\n",
    "        normalized_tensor = (reshspe_weight / self.scales)\n",
    "        weight_list = normalized_tensor.split(normalized_tensor.shape[0]//self.codebook_num,dim = 0)\n",
    "        nearest_indices_list = []\n",
    "        index = 0\n",
    "        for weight in weight_list:\n",
    "            nearest_indices=get_nearest_indices(S=None,W = weight.view(-1,self.centroid_len),shape = weight.shape,centroids=self.codebooks[index])\n",
    "            nearest_indices_list.append(nearest_indices.unsqueeze(0))\n",
    "            print(\"shape:\",nearest_indices.shape)\n",
    "            index +=1\n",
    "        nearest_indices_merge = torch.cat(nearest_indices_list,dim = 0)\n",
    "        print(nearest_indices_merge.shape)\n",
    "        self.codes.data  =nearest_indices_merge\n",
    "    def forward(self):\n",
    "        weight = self.differentiable_dequantize()\n",
    "        return weight.to(self.dev)\n",
    "    def prune_wanda(self,sparsity_ratio = 0.2):\n",
    "        W_metric = torch.abs(self.weight.data) * torch.sqrt(self.scaler_row.reshape((1,-1)))\n",
    "        W_mask = (torch.zeros_like(W_metric) == 1)\n",
    "        sort_res = torch.sort(W_metric, dim=-1, stable=True)\n",
    "        indices = sort_res[1][:,:int(W_metric.shape[1]*sparsity_ratio)]\n",
    "        W_mask.scatter_(1, indices, True)\n",
    "        self.layer.weight.data[W_mask] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "inp = torch.nn.Linear(1024,1024).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "tensor(255, device='cuda:0')\n",
      "tensor(255, device='cuda:0')\n",
      "tensor(0.0293, device='cuda:0')\n",
      "tensor([[ 38, 192, 214,  ..., 114, 144, 183],\n",
      "        [ 66, 221, 174,  ...,  87, 230,  48]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "a  = Quantization(layer=inp,bolck_size=128,codebook_num=2)\n",
    "cnt_codes = a.codes.clone()\n",
    "print(cnt_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([131072, 1, 4])\n",
      "torch.Size([1, 256, 4])\n",
      "torch.Size([131072, 1, 4])\n",
      "shape: torch.Size([131072])\n",
      "torch.Size([131072, 1, 4])\n",
      "torch.Size([1, 256, 4])\n",
      "torch.Size([131072, 1, 4])\n",
      "shape: torch.Size([131072])\n",
      "torch.Size([2, 131072])\n",
      "tensor(261121, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "a.update_index()\n",
    "print((a.codes!=cnt_codes).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 131072])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_codes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[ 0.1130,  0.1182, -0.0421, -0.1128],\n",
      "         [-0.1178,  0.1117,  0.0520, -0.0526],\n",
      "         [ 0.0144, -0.0559,  0.0112, -0.0201],\n",
      "         ...,\n",
      "         [-0.1221, -0.1143, -0.0078,  0.1190],\n",
      "         [ 0.0592, -0.0468, -0.0631, -0.1185],\n",
      "         [ 0.0466, -0.0425, -0.1206, -0.0551]],\n",
      "\n",
      "        [[ 0.1216, -0.0103,  0.0480,  0.1091],\n",
      "         [ 0.1179, -0.0255, -0.0401, -0.1157],\n",
      "         [ 0.0006,  0.0678, -0.0354,  0.0707],\n",
      "         ...,\n",
      "         [-0.0338, -0.1109,  0.1213,  0.1103],\n",
      "         [-0.1174,  0.1184, -0.0505,  0.1202],\n",
      "         [-0.1136,  0.1188,  0.1160,  0.1093]]], device='cuda:0',\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(a.codebooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2097152, 1, 4])\n",
      "torch.Size([1, 256, 4])\n",
      "torch.Size([2097152, 1, 4])\n",
      "torch.Size([2097152, 1, 4])\n",
      "torch.Size([1, 256, 4])\n",
      "torch.Size([2097152, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "a.update_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.codes-cnt_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 256, 4])\n",
      "Parameter containing:\n",
      "tensor([[  2, 123, 203,  ..., 254, 114, 165],\n",
      "        [435, 318, 304,  ..., 489, 418, 379]])\n",
      "torch.Size([262144])\n",
      "tensor([[ 0.0065,  0.0081,  0.0252,  ..., -0.0248,  0.0091, -0.0238],\n",
      "        [-0.0232,  0.0039, -0.0068,  ...,  0.0117,  0.0238, -0.0078],\n",
      "        [-0.0062, -0.0201, -0.0252,  ...,  0.0076, -0.0246, -0.0067],\n",
      "        ...,\n",
      "        [ 0.0053,  0.0101,  0.0072,  ...,  0.0139, -0.0224,  0.0253],\n",
      "        [-0.0261,  0.0053, -0.0069,  ...,  0.0244, -0.0058, -0.0122],\n",
      "        [ 0.0257,  0.0243,  0.0063,  ..., -0.0098,  0.0127,  0.0253]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "codebook_num = a.codebook_num\n",
    "codebook_flatten = a.codebooks.flatten(0,1)\n",
    "codes = a.codes\n",
    "print(a.codebooks.shape)\n",
    "for i in range(1,codebook_num):\n",
    "    codes[i,:]+=a.centroids_num\n",
    "codebook_offsets = torch.arange(0,a.layer.weight.data.numel()//4)\n",
    "print(codes)\n",
    "print(codebook_offsets.shape)\n",
    "reconstruct_weight = F.embedding_bag(codes.flatten(),a.codebooks.flatten(0,1),codebook_offsets,mode=\"sum\")\n",
    "print(reconstruct_weight.view(a.layer.weight.data.shape)*a.scales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original B: tensor([[-1.7957, -0.5694,  1.1150, -1.5595,  1.2649,  0.5069, -1.8813,  0.7021,\n",
      "          1.8290,  0.5245],\n",
      "        [-1.5341, -0.6747,  0.2805,  1.1678,  2.6085, -0.4850,  0.1465,  0.5565,\n",
      "         -0.7984, -0.4044],\n",
      "        [ 0.4942, -1.0950, -0.8076, -0.5437,  0.9076, -0.8676,  0.4262, -0.4891,\n",
      "         -1.2001, -0.6039],\n",
      "        [-0.9421,  0.8060, -0.5594,  0.2004,  0.2072,  0.0192, -1.1937,  1.2918,\n",
      "         -0.1507, -0.2783],\n",
      "        [-0.5567, -1.7914, -0.4568, -0.2659, -0.5638, -0.9680, -0.4975,  0.5015,\n",
      "         -1.4597,  0.1531]])\n",
      "Sorted B: tensor([[-1.7957, -0.5694,  1.1150, -1.5595,  1.2649,  0.5069, -1.8813,  0.7021,\n",
      "          1.8290,  0.5245],\n",
      "        [-0.9421,  0.8060, -0.5594,  0.2004,  0.2072,  0.0192, -1.1937,  1.2918,\n",
      "         -0.1507, -0.2783],\n",
      "        [-0.5567, -1.7914, -0.4568, -0.2659, -0.5638, -0.9680, -0.4975,  0.5015,\n",
      "         -1.4597,  0.1531],\n",
      "        [-1.5341, -0.6747,  0.2805,  1.1678,  2.6085, -0.4850,  0.1465,  0.5565,\n",
      "         -0.7984, -0.4044],\n",
      "        [ 0.4942, -1.0950, -0.8076, -0.5437,  0.9076, -0.8676,  0.4262, -0.4891,\n",
      "         -1.2001, -0.6039]])\n",
      "Restored B: tensor([[-1.7957, -0.5694,  1.1150, -1.5595,  1.2649,  0.5069, -1.8813,  0.7021,\n",
      "          1.8290,  0.5245],\n",
      "        [-1.5341, -0.6747,  0.2805,  1.1678,  2.6085, -0.4850,  0.1465,  0.5565,\n",
      "         -0.7984, -0.4044],\n",
      "        [ 0.4942, -1.0950, -0.8076, -0.5437,  0.9076, -0.8676,  0.4262, -0.4891,\n",
      "         -1.2001, -0.6039],\n",
      "        [-0.9421,  0.8060, -0.5594,  0.2004,  0.2072,  0.0192, -1.1937,  1.2918,\n",
      "         -0.1507, -0.2783],\n",
      "        [-0.5567, -1.7914, -0.4568, -0.2659, -0.5638, -0.9680, -0.4975,  0.5015,\n",
      "         -1.4597,  0.1531]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 假设的数据\n",
    "N = 5\n",
    "A = torch.tensor([0, 1, 1, 0, 0])  # 类别Tensor\n",
    "B = torch.randn(N, 10)  # 假设的矩阵B\n",
    "\n",
    "# 根据A中的类别对B进行重排\n",
    "sorted_indices = torch.argsort(A)\n",
    "B_sorted = torch.index_select(B, 0, sorted_indices)\n",
    "\n",
    "# 复原到原始顺序\n",
    "# 首先获取复原时的索引，即对sorted_indices进行再次排序的索引\n",
    "restore_indices = torch.argsort(sorted_indices)\n",
    "B_restored = torch.index_select(B_sorted, 0, restore_indices)\n",
    "\n",
    "print(\"Original B:\", B)\n",
    "print(\"Sorted B:\", B_sorted)\n",
    "print(\"Restored B:\", B_restored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "l = torch.nn.Linear(1024,1024,bias=False)\n",
    "x = torch.rand((2,1024))\n",
    "res1 = l(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3014,  0.3794,  0.0551,  ..., -0.1906, -0.1463,  0.5322],\n",
       "        [ 0.2058,  0.1400,  0.3062,  ..., -0.0755,  0.1639,  0.8108]],\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3014,  0.2058],\n",
      "        [ 0.3794,  0.1400],\n",
      "        [ 0.0551,  0.3062],\n",
      "        ...,\n",
      "        [-0.1906, -0.0755],\n",
      "        [-0.1463,  0.1639],\n",
      "        [ 0.5322,  0.8108]])\n"
     ]
    }
   ],
   "source": [
    "res2 = x@l.weight.data.t()\n",
    "print(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0025, -0.0523],\n",
       "        [ 0.1277,  0.2450],\n",
       "        [ 0.1829, -0.1117],\n",
       "        ...,\n",
       "        [-0.0798, -0.0165],\n",
       "        [ 0.0814,  0.2337],\n",
       "        [-0.2363, -0.3942]])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= torch.rand(5,6).cpu().double()*100\n",
    "b= torch.rand(5,6).cpu().double()*666\n",
    "c=torch.rand(6,7).cpu().double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = a.norm(p=2, dim=1, keepdim=True).float().double()*10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1561e+09, -1.2428e+09, -1.0333e+09, -1.3948e+09, -1.3496e+09,\n",
       "         -1.4515e+09, -1.3786e+09],\n",
       "        [-2.1541e+08, -1.7501e+08, -5.1016e+08, -2.0091e+08, -5.9879e+08,\n",
       "         -6.4112e+08, -3.6177e+08],\n",
       "        [-1.6216e+09, -8.0214e+08, -1.6077e+09, -7.1721e+08, -2.2656e+09,\n",
       "         -2.1320e+09, -1.4620e+09],\n",
       "        [-1.2804e+09, -9.6570e+08, -1.8153e+09, -1.5185e+09, -1.8825e+09,\n",
       "         -1.7938e+09, -1.3736e+09],\n",
       "        [-1.6828e+09, -9.2218e+08, -1.2531e+09, -1.0505e+09, -1.7726e+09,\n",
       "         -1.5350e+09, -1.3210e+09]], dtype=torch.float64)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((a-b)*scales)@c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3283e-10,  0.0000e+00,  0.0000e+00, -2.3283e-10,  2.3283e-10,\n",
       "         -2.3283e-10,  2.3283e-10],\n",
       "        [ 2.9104e-11, -2.9104e-11,  5.8208e-11,  2.9104e-11,  0.0000e+00,\n",
       "          0.0000e+00, -5.8208e-11],\n",
       "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -4.6566e-10,\n",
       "          4.6566e-10, -2.3283e-10],\n",
       "        [ 2.3283e-10,  1.1642e-10,  0.0000e+00, -2.3283e-10,  0.0000e+00,\n",
       "          2.3283e-10, -2.3283e-10],\n",
       "        [ 2.3283e-10,  1.1642e-10, -2.3283e-10,  0.0000e+00,  0.0000e+00,\n",
       "         -2.3283e-10, -2.3283e-10]], dtype=torch.float64)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scales = a.norm(p=2, dim=1, keepdim=True).float().double()*10\n",
    "(((a-b)@c)*scales) - (((a*scales-b*scales))@c)\n",
    "# scale 的运算可以提到最外面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7849233.9964, dtype=torch.float64)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(((a-b)@c)*scales).norm(p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7634229.0188],\n",
       "        [5799491.6243],\n",
       "        [9532574.3193],\n",
       "        [7950872.9884],\n",
       "        [6794302.0308]], dtype=torch.float64)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(((a-b)@c)).norm(p=2)*scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每个子向量最佳匹配的码本向量索引: tensor([ 99, 191, 234,  ..., 221, 153,  32], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "# 输入参数保持不变\n",
    "M = 256\n",
    "L_C = 4\n",
    "L_V = 4096*4096\n",
    "\n",
    "# 创建随机输入\n",
    "C = torch.rand(M, L_C).cuda()\n",
    "V = torch.rand(L_V).cuda()\n",
    "inp = torch.rand(L_V).cuda()\n",
    "\n",
    "# 重塑\n",
    "num_segments = L_V // L_C\n",
    "V_reshaped = V.view(num_segments, L_C)\n",
    "inp_reshaped = inp.view(num_segments, L_C).cuda()\n",
    "\n",
    "# 定义分批处理的大小\n",
    "batch_size = 1024*1024  # 根据可用内存调整\n",
    "\n",
    "# 初始化最佳匹配索引的列表\n",
    "min_distance_indices = []\n",
    "\n",
    "# 分批处理\n",
    "for i in range(0, num_segments, batch_size):\n",
    "    end_i = min(i + batch_size, num_segments)\n",
    "    V_batch = V_reshaped[i:end_i].unsqueeze(1).expand(-1, M, -1)\n",
    "    inp_batch = inp_reshaped[i:end_i].unsqueeze(1).expand(-1, M, -1)\n",
    "    \n",
    "    # 计算加权欧几里得距离\n",
    "    weighted_diff = (C.unsqueeze(0).expand(end_i-i, -1, -1) - V_batch) ** 2 * inp_batch\n",
    "    distances = torch.sqrt(weighted_diff.sum(dim=2))\n",
    "    \n",
    "    # 找到最佳匹配的索引\n",
    "    batch_min_indices = torch.argmin(distances, dim=1)\n",
    "    min_distance_indices.append(batch_min_indices)\n",
    "\n",
    "# 合并结果\n",
    "min_distance_indices1 = torch.cat(min_distance_indices)\n",
    "\n",
    "print(f\"每个子向量最佳匹配的码本向量索引: {min_distance_indices1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacty of 39.39 GiB of which 14.47 GiB is free. Including non-PyTorch memory, this process has 24.92 GiB memory in use. Of the allocated memory 21.31 GiB is allocated by PyTorch, and 3.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m/home/quant/AQLM-main/notebooks/kmeans.ipynb Cell 30\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.242.193/home/quant/AQLM-main/notebooks/kmeans.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m C_expanded \u001b[39m=\u001b[39m C\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mexpand(num_segments, M, L_C)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.242.193/home/quant/AQLM-main/notebooks/kmeans.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# 计算加权欧几里得距离\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B192.168.242.193/home/quant/AQLM-main/notebooks/kmeans.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m weighted_diff \u001b[39m=\u001b[39m (C_expanded \u001b[39m-\u001b[39;49m V_reshaped) \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m \u001b[39m2\u001b[39;49m \u001b[39m*\u001b[39m inp_reshaped\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.242.193/home/quant/AQLM-main/notebooks/kmeans.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m distances \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msqrt(weighted_diff\u001b[39m.\u001b[39msum(dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B192.168.242.193/home/quant/AQLM-main/notebooks/kmeans.ipynb#X41sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mprint\u001b[39m(weighted_diff\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/.conda/envs/AWQ/lib/python3.10/site-packages/torch/_tensor.py:40\u001b[0m, in \u001b[0;36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[39mif\u001b[39;00m has_torch_function(args):\n\u001b[1;32m     39\u001b[0m         \u001b[39mreturn\u001b[39;00m handle_torch_function(wrapped, args, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 40\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     41\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacty of 39.39 GiB of which 14.47 GiB is free. Including non-PyTorch memory, this process has 24.92 GiB memory in use. Of the allocated memory 21.31 GiB is allocated by PyTorch, and 3.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "def update_index(batch_size,important,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0,  ..., 0, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_distance_indices1-min_distance_indices2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin = torch.nn.Linear(3,5,bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.rand(7,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2496, -0.2233,  0.3125,  0.1016, -0.2145],\n",
       "        [ 0.2090, -0.4283,  0.2185,  0.1516, -0.2442],\n",
       "        [ 0.1277, -0.4315,  0.1069,  0.1331, -0.2003],\n",
       "        [ 0.4721, -0.5911,  0.5819,  0.2041, -0.4811],\n",
       "        [ 0.2023, -0.2271,  0.2325,  0.1157, -0.1680],\n",
       "        [ 0.2309, -0.3092,  0.2754,  0.1145, -0.2326],\n",
       "        [ 0.1323, -0.4062,  0.1227,  0.1190, -0.2032]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin(test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2496, -0.2233,  0.3125,  0.1016, -0.2145],\n",
       "        [ 0.2090, -0.4283,  0.2185,  0.1516, -0.2442],\n",
       "        [ 0.1277, -0.4315,  0.1069,  0.1331, -0.2003],\n",
       "        [ 0.4721, -0.5911,  0.5819,  0.2041, -0.4811],\n",
       "        [ 0.2023, -0.2271,  0.2325,  0.1157, -0.1680],\n",
       "        [ 0.2309, -0.3092,  0.2754,  0.1145, -0.2326],\n",
       "        [ 0.1323, -0.4062,  0.1227,  0.1190, -0.2032]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test@lin.weight.data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a= torch.rand((2,6))\n",
    "s= torch.ones(2)\n",
    "s[1]=2\n",
    "b= torch.rand((3,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(s.unsqueeze(0).expand(10, -1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 1, 2])\n",
      "torch.Size([1, 3, 2])\n",
      "torch.Size([6, 1, 2])\n",
      "tensor([[0.1453, 0.7746, 0.1524],\n",
      "        [0.0386, 0.5657, 0.0353],\n",
      "        [0.4287, 0.1449, 0.2916],\n",
      "        [1.6086, 0.8168, 1.2795],\n",
      "        [1.1933, 0.3701, 0.8724],\n",
      "        [0.0426, 1.7083, 0.1436]])\n"
     ]
    }
   ],
   "source": [
    "# print(s1.shape)\n",
    "a1 = a.view(-1,b.shape[1])\n",
    "a1 = a1.unsqueeze(1)\n",
    "s1 = s.repeat_interleave(a.shape[1]).view(a1.shape)\n",
    "print(a1.shape)\n",
    "b1 = b.unsqueeze(0)\n",
    "print(b1.shape)\n",
    "print(s1.shape)\n",
    "print(((a1-b1)**2*s1).sum(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[3.9769e-01, 7.0685e-04, 3.0995e-01, 1.9730e-01],\n",
      "         [7.3857e-03, 1.0877e+00, 1.7051e-03, 1.5028e-01],\n",
      "         [1.3659e+00, 1.7461e-02, 1.0101e-01, 5.4490e-01],\n",
      "         [8.7841e-01, 1.0223e-03, 4.7654e-01, 2.7275e-01],\n",
      "         [1.6983e+00, 2.5771e-02, 6.7909e-02, 3.9137e-02],\n",
      "         [2.8442e-01, 1.9815e-02, 1.9276e-04, 2.3848e-01]],\n",
      "\n",
      "        [[1.3231e-02, 1.8867e-02, 1.7542e-01, 1.2636e-01],\n",
      "         [1.8461e-01, 8.6892e-01, 8.7285e-01, 8.9370e-02],\n",
      "         [4.2654e-01, 4.5669e-04, 1.6728e+00, 4.2179e-01],\n",
      "         [1.7777e-01, 2.0375e-02, 8.1362e-02, 1.8796e-01],\n",
      "         [6.2027e-01, 2.4766e-03, 5.1117e-01, 1.1907e-02],\n",
      "         [3.1361e-04, 8.9980e-04, 9.7899e-01, 1.5970e-01]],\n",
      "\n",
      "        [[3.8673e-01, 1.4961e+00, 7.6097e-01, 4.0581e-02],\n",
      "         [5.9584e-03, 2.3602e-02, 1.2738e-01, 6.6549e-02],\n",
      "         [1.3455e+00, 1.1330e+00, 4.8886e-06, 8.5630e-03],\n",
      "         [8.6208e-01, 1.5093e+00, 1.0119e+00, 1.5222e-02],\n",
      "         [1.6755e+00, 1.0733e+00, 3.3201e-01, 2.0053e-01],\n",
      "         [2.7517e-01, 1.1147e+00, 9.1036e-02, 2.4741e-02]],\n",
      "\n",
      "        [[8.7831e-02, 1.4719e+00, 9.5304e-02, 5.4794e-01],\n",
      "         [6.1666e-02, 2.0650e-02, 4.2734e-02, 4.6746e-01],\n",
      "         [6.9628e-01, 1.1119e+00, 3.2017e-01, 1.0696e+00],\n",
      "         [3.6357e-01, 1.4850e+00, 1.9563e-01, 6.6962e-01],\n",
      "         [9.3878e-01, 1.0529e+00, 1.5825e-04, 2.4392e-01],\n",
      "         [3.9619e-02, 1.0938e+00, 6.8591e-02, 6.1527e-01]],\n",
      "\n",
      "        [[1.4365e-01, 5.1337e-01, 2.7315e-03, 9.4577e-01],\n",
      "         [2.7450e-02, 1.2462e-01, 2.1453e-01, 8.3903e-01],\n",
      "         [8.4104e-01, 3.1111e-01, 6.7615e-01, 1.6040e+00],\n",
      "         [4.7007e-01, 5.2112e-01, 3.4541e-02, 1.1037e+00],\n",
      "         [1.1058e+00, 2.8024e-01, 5.9473e-02, 5.2730e-01],\n",
      "         [7.9350e-02, 3.0156e-01, 2.6868e-01, 1.0336e+00]],\n",
      "\n",
      "        [[6.7688e-03, 1.0156e+00, 9.0797e-01, 1.2839e-01],\n",
      "         [3.9308e-01, 3.8110e-03, 1.9135e-01, 9.1080e-02],\n",
      "         [2.0775e-01, 7.2089e-01, 6.1355e-03, 4.2550e-01],\n",
      "         [5.0325e-02, 1.0265e+00, 1.1804e+00, 1.9044e-01],\n",
      "         [3.4842e-01, 6.7348e-01, 4.3131e-01, 1.2536e-02],\n",
      "         [3.2253e-02, 7.0632e-01, 1.4612e-01, 1.6199e-01]],\n",
      "\n",
      "        [[1.5104e-01, 2.2344e-01, 5.8704e-02, 9.4430e-01],\n",
      "         [2.4352e-02, 3.5619e-01, 7.4609e-02, 8.3764e-01],\n",
      "         [8.5879e-01, 9.8577e-02, 3.9975e-01, 1.6021e+00],\n",
      "         [4.8336e-01, 2.2856e-01, 1.4128e-01, 1.1021e+00],\n",
      "         [1.1261e+00, 8.1553e-02, 2.8992e-03, 5.2620e-01],\n",
      "         [8.4868e-02, 9.3234e-02, 1.0780e-01, 1.0321e+00]],\n",
      "\n",
      "        [[8.7586e-03, 4.6483e-02, 2.5074e-04, 1.9685e-01],\n",
      "         [2.0349e-01, 7.2917e-01, 2.8225e-01, 1.4989e-01],\n",
      "         [3.9899e-01, 3.2345e-03, 7.9278e-01, 5.4415e-01],\n",
      "         [1.6015e-01, 4.8834e-02, 1.3866e-02, 2.7223e-01],\n",
      "         [5.8696e-01, 8.1097e-04, 9.7324e-02, 3.8938e-02],\n",
      "         [1.3915e-05, 2.3277e-03, 3.4392e-01, 2.3799e-01]],\n",
      "\n",
      "        [[3.9676e-01, 7.2273e-01, 1.1463e-01, 2.1476e-01],\n",
      "         [1.3796e+00, 4.8128e-02, 7.2934e-01, 1.6556e-01],\n",
      "         [8.4304e-03, 4.7804e-01, 1.4717e+00, 5.7366e-01],\n",
      "         [1.0451e-01, 7.3191e-01, 4.2020e-02, 2.9321e-01],\n",
      "         [1.8196e-03, 4.3958e-01, 4.0286e-01, 4.7117e-02],\n",
      "         [5.2883e-01, 4.6619e-01, 8.2662e-01, 2.5763e-01]],\n",
      "\n",
      "        [[1.7168e-01, 1.4427e+00, 1.6205e-01, 8.1583e-01],\n",
      "         [9.1974e-01, 1.7322e-02, 8.4269e-01, 7.1692e-01],\n",
      "         [1.5309e-02, 1.0866e+00, 1.6310e+00, 1.4333e+00],\n",
      "         [1.1608e-02, 1.4557e+00, 7.2340e-02, 9.6296e-01],\n",
      "         [6.6669e-02, 1.0282e+00, 4.8816e-01, 4.3149e-01],\n",
      "         [2.6180e-01, 1.0687e+00, 9.4704e-01, 8.9755e-01]],\n",
      "\n",
      "        [[1.8983e-02, 1.0151e+00, 1.8918e-03, 3.6919e-02],\n",
      "         [4.6576e-01, 3.8409e-03, 2.2273e-01, 1.8392e-02],\n",
      "         [1.6024e-01, 7.2048e-01, 6.9065e-01, 2.3632e-01],\n",
      "         [2.8503e-02, 1.0260e+00, 3.1358e-02, 7.3015e-02],\n",
      "         [2.8598e-01, 6.7309e-01, 6.3827e-02, 2.9390e-03],\n",
      "         [5.5270e-02, 7.0591e-01, 2.7785e-01, 5.5837e-02]],\n",
      "\n",
      "        [[2.4396e-02, 1.0713e+00, 2.9142e-02, 1.8637e-02],\n",
      "         [4.9123e-01, 1.1885e-03, 1.1883e-01, 6.3989e-03],\n",
      "         [1.4583e-01, 7.6792e-01, 4.9538e-01, 1.8533e-01],\n",
      "         [2.2624e-02, 1.0825e+00, 9.2598e-02, 4.6048e-02],\n",
      "         [2.6662e-01, 7.1896e-01, 1.5731e-02, 1.2064e-02],\n",
      "         [6.4267e-02, 7.5288e-01, 1.5992e-01, 3.2643e-02]],\n",
      "\n",
      "        [[6.5787e-02, 5.8865e-01, 1.6698e-01, 6.9157e-01],\n",
      "         [6.4189e-01, 9.1372e-02, 1.1406e-02, 6.0076e-01],\n",
      "         [7.9288e-02, 3.7029e-01, 2.1707e-01, 1.2670e+00],\n",
      "         [2.5115e-03, 5.9695e-01, 2.9401e-01, 8.2752e-01],\n",
      "         [1.7310e-01, 3.3653e-01, 1.2657e-02, 3.4252e-01],\n",
      "         [1.2518e-01, 3.5986e-01, 2.6236e-02, 7.6697e-01]],\n",
      "\n",
      "        [[6.9777e-02, 1.9194e-03, 1.3186e-02, 1.4191e-01],\n",
      "         [7.8701e-02, 1.0521e+00, 3.9723e-01, 1.0252e-01],\n",
      "         [6.4356e-01, 1.3206e-02, 9.7886e-01, 4.4982e-01],\n",
      "         [3.2576e-01, 2.4203e-03, 3.5193e-04, 2.0682e-01],\n",
      "         [8.7741e-01, 2.0538e-02, 1.6889e-01, 1.6991e-02],\n",
      "         [2.7834e-02, 1.5263e-02, 4.6983e-01, 1.7712e-01]],\n",
      "\n",
      "        [[1.1886e-01, 1.3377e-02, 5.9340e-01, 2.1343e-02],\n",
      "         [7.9111e-01, 9.0984e-01, 6.4967e-02, 4.1053e-02],\n",
      "         [3.7372e-02, 1.8548e-03, 1.0863e-02, 2.1872e-02],\n",
      "         [1.4554e-03, 1.4652e-02, 8.1705e-01, 4.6269e-03],\n",
      "         [1.0745e-01, 5.1070e-03, 2.2485e-01, 1.5401e-01],\n",
      "         [1.9543e-01, 2.6723e-03, 3.9884e-02, 1.0391e-02]],\n",
      "\n",
      "        [[3.9676e-01, 5.8188e-02, 1.3758e-03, 1.6459e-01],\n",
      "         [1.3796e+00, 6.8607e-01, 3.0529e-01, 1.2192e-01],\n",
      "         [8.4298e-03, 6.8055e-03, 8.3108e-01, 4.8955e-01],\n",
      "         [1.0451e-01, 6.0816e-02, 9.3116e-03, 2.3403e-01],\n",
      "         [1.8199e-03, 2.9269e-03, 1.1104e-01, 2.5389e-02],\n",
      "         [5.2882e-01, 5.4567e-03, 3.6930e-01, 2.0236e-01]],\n",
      "\n",
      "        [[4.3815e-01, 5.1992e-02, 6.3075e-02, 4.5906e-03],\n",
      "         [1.3745e-02, 7.0812e-01, 5.8765e-01, 1.5445e-02],\n",
      "         [1.4400e+00, 4.8012e-03, 1.2672e+00, 5.1180e-02],\n",
      "         [9.3805e-01, 5.4477e-02, 1.3820e-02, 1.0645e-04],\n",
      "         [1.7808e+00, 1.6724e-03, 2.9952e-01, 9.8664e-02],\n",
      "         [3.1878e-01, 3.6801e-03, 6.7529e-01, 5.5685e-04]],\n",
      "\n",
      "        [[3.2347e-02, 5.3654e-01, 1.6886e-02, 2.2156e-01],\n",
      "         [5.2496e-01, 1.1359e-01, 4.1652e-01, 1.7154e-01],\n",
      "         [1.2832e-01, 3.2920e-01, 1.0090e+00, 5.8474e-01],\n",
      "         [1.6066e-02, 5.4446e-01, 1.3267e-05, 3.0115e-01],\n",
      "         [2.4275e-01, 2.9742e-01, 1.8154e-01, 5.0330e-02],\n",
      "         [7.6823e-02, 3.1938e-01, 4.9078e-01, 2.6508e-01]],\n",
      "\n",
      "        [[3.0819e-01, 1.1363e-02, 5.0773e-01, 1.5962e-01],\n",
      "         [1.0937e-04, 1.3832e+00, 3.8854e-02, 2.0798e-01],\n",
      "         [1.1951e+00, 7.0397e-02, 2.6242e-02, 1.1140e-02],\n",
      "         [7.4262e-01, 1.0244e-02, 7.1595e-01, 1.0333e-01],\n",
      "         [1.5072e+00, 8.6271e-02, 1.7340e-01, 4.1716e-01],\n",
      "         [2.0961e-01, 7.5049e-02, 2.0146e-02, 1.2629e-01]],\n",
      "\n",
      "        [[9.3657e-03, 5.1279e-02, 1.4471e-01, 1.9548e-01],\n",
      "         [4.1148e-01, 7.1076e-01, 1.8233e-02, 1.4869e-01],\n",
      "         [1.9474e-01, 4.5863e-03, 2.4417e-01, 5.4186e-01],\n",
      "         [4.4028e-02, 5.3747e-02, 2.6419e-01, 2.7061e-01],\n",
      "         [3.3151e-01, 1.5466e-03, 7.1017e-03, 3.8327e-02],\n",
      "         [3.7673e-02, 3.4924e-03, 3.6179e-02, 2.3647e-01]],\n",
      "\n",
      "        [[1.9716e-02, 2.8609e-01, 1.3559e-01, 1.0117e-01],\n",
      "         [4.6937e-01, 2.8584e-01, 2.1672e-02, 6.8407e-02],\n",
      "         [1.5813e-01, 1.4149e-01, 2.5636e-01, 3.7461e-01],\n",
      "         [2.7620e-02, 2.9188e-01, 2.5181e-01, 1.5693e-01],\n",
      "         [2.8317e-01, 1.2093e-01, 5.1966e-03, 5.1431e-03],\n",
      "         [5.6516e-02, 1.3507e-01, 4.0962e-02, 1.3121e-01]],\n",
      "\n",
      "        [[1.1177e-01, 4.6290e-01, 9.5499e-01, 6.1979e-01],\n",
      "         [7.7265e-01, 1.5143e-01, 2.1326e-01, 5.3398e-01],\n",
      "         [4.1516e-02, 2.7211e-01, 1.0545e-02, 1.1691e+00],\n",
      "         [7.6789e-04, 4.7026e-01, 1.2339e+00, 7.4881e-01],\n",
      "         [1.1440e-01, 2.4330e-01, 4.6390e-01, 2.9258e-01],\n",
      "         [1.8631e-01, 2.6319e-01, 1.6534e-01, 6.9126e-01]],\n",
      "\n",
      "        [[3.5535e-01, 4.2911e-03, 1.8190e-01, 1.4353e-01],\n",
      "         [1.3014e+00, 1.2883e+00, 8.8724e-01, 1.0390e-01],\n",
      "         [3.3689e-03, 5.0280e-02, 1.6927e+00, 4.5271e-01],\n",
      "         [8.3816e-02, 3.6144e-03, 8.5796e-02, 2.0878e-01],\n",
      "         [5.8419e-03, 6.3821e-02, 5.2220e-01, 1.7556e-02],\n",
      "         [4.8085e-01, 5.4223e-02, 9.9423e-01, 1.7894e-01]],\n",
      "\n",
      "        [[3.4219e-03, 7.7097e-01, 5.0875e-01, 3.5410e-01],\n",
      "         [2.3638e-01, 3.6660e-02, 3.9137e-02, 2.9003e-01],\n",
      "         [3.5589e-01, 5.1742e-01, 2.6011e-02, 7.9041e-01],\n",
      "         [1.3330e-01, 7.8045e-01, 7.1716e-01, 4.5311e-01],\n",
      "         [5.3442e-01, 4.7738e-01, 1.7400e-01, 1.2160e-01],\n",
      "         [1.5070e-03, 5.0509e-01, 2.0350e-02, 4.0861e-01]],\n",
      "\n",
      "        [[1.7653e-01, 3.6689e-01, 8.3320e-01, 2.4883e-02],\n",
      "         [9.3092e-01, 2.1511e-01, 1.5790e-01, 4.5910e-02],\n",
      "         [1.3905e-02, 1.9980e-01, 1.4632e-03, 1.8562e-02],\n",
      "         [1.2893e-02, 3.7344e-01, 1.0949e+00, 6.3474e-03],\n",
      "         [6.3702e-02, 1.7522e-01, 3.8027e-01, 1.6329e-01],\n",
      "         [2.6778e-01, 1.9216e-01, 1.1709e-01, 1.2902e-02]],\n",
      "\n",
      "        [[5.0692e-01, 1.1104e-02, 1.3052e-01, 2.4883e-02],\n",
      "         [2.7987e-02, 1.3804e+00, 2.3767e-02, 4.5911e-02],\n",
      "         [1.5626e+00, 6.9750e-02, 2.6345e-01, 1.8561e-02],\n",
      "         [1.0375e+00, 9.9980e-03, 2.4489e-01, 6.3479e-03],\n",
      "         [1.9169e+00, 8.5555e-02, 4.2429e-03, 1.6330e-01],\n",
      "         [3.7781e-01, 7.4381e-02, 4.3823e-02, 1.2902e-02]],\n",
      "\n",
      "        [[2.5805e-01, 8.2915e-01, 7.0363e-01, 1.6308e-03],\n",
      "         [1.1081e+00, 2.5262e-02, 1.0458e-01, 9.3910e-03],\n",
      "         [9.0488e-04, 5.6528e-01, 1.2757e-03, 6.4313e-02],\n",
      "         [4.0556e-02, 8.3898e-01, 9.4559e-01, 1.4204e-03],\n",
      "         [2.7079e-02, 5.2338e-01, 2.9452e-01, 8.2219e-02],\n",
      "         [3.6640e-01, 5.5238e-01, 7.1940e-02, 1.4234e-05]],\n",
      "\n",
      "        [[1.8539e-01, 1.1854e+00, 4.7009e-01, 7.1987e-02],\n",
      "         [1.3024e-02, 3.7124e-04, 2.8967e-02, 1.0551e-01],\n",
      "         [9.3826e-01, 8.6500e-01, 3.5688e-02, 6.5947e-04],\n",
      "         [5.4342e-01, 1.1972e+00, 6.7112e-01, 3.6188e-02],\n",
      "         [1.2169e+00, 8.1299e-01, 1.5171e-01, 2.6487e-01],\n",
      "         [1.1106e-01, 8.4903e-01, 1.3230e-02, 5.0242e-02]],\n",
      "\n",
      "        [[7.4329e-02, 7.9466e-01, 3.1455e-02, 5.3665e-03],\n",
      "         [6.6802e-01, 3.1711e-02, 4.7996e-01, 2.7998e-04],\n",
      "         [7.0458e-02, 5.3687e-01, 1.1065e+00, 1.3487e-01],\n",
      "         [1.1541e-03, 8.0430e-01, 1.9157e-03, 2.2900e-02],\n",
      "         [1.5993e-01, 4.9606e-01, 2.2419e-01, 2.9963e-02],\n",
      "         [1.3686e-01, 5.2430e-01, 5.5946e-01, 1.3786e-02]],\n",
      "\n",
      "        [[1.3393e-01, 6.4189e-01, 2.2584e-02, 4.9055e-01],\n",
      "         [8.2930e-01, 7.2003e-02, 4.4318e-01, 4.1457e-01],\n",
      "         [2.9619e-02, 4.1275e-01, 1.0503e+00, 9.8879e-01],\n",
      "         [3.5242e-03, 6.5055e-01, 2.7856e-04, 6.0601e-01],\n",
      "         [9.3989e-02, 3.7707e-01, 1.9928e-01, 2.0615e-01],\n",
      "         [2.1464e-01, 4.0174e-01, 5.1968e-01, 5.5435e-01]],\n",
      "\n",
      "        [[2.9044e-01, 3.5716e-01, 1.8024e-02, 4.1277e-01],\n",
      "         [3.3266e-05, 2.2267e-01, 4.2209e-01, 3.4333e-01],\n",
      "         [1.1599e+00, 1.9264e-01, 1.0177e+00, 8.7695e-01],\n",
      "         [7.1492e-01, 3.6363e-01, 4.4098e-07, 5.1918e-01],\n",
      "         [1.4677e+00, 1.6852e-01, 1.8523e-01, 1.5691e-01],\n",
      "         [1.9501e-01, 1.8514e-01, 4.9683e-01, 4.7145e-01]],\n",
      "\n",
      "        [[1.0379e-03, 5.1001e-01, 4.5633e-02, 2.4575e-02],\n",
      "         [2.6263e-01, 1.2628e-01, 9.1094e-02, 4.5491e-02],\n",
      "         [3.2523e-01, 3.0849e-01, 4.3683e-01, 1.8829e-02],\n",
      "         [1.1480e-01, 5.1773e-01, 1.2055e-01, 6.1925e-03],\n",
      "         [4.9669e-01, 2.7776e-01, 6.8089e-03, 1.6250e-01],\n",
      "         [4.2381e-03, 2.9899e-01, 1.2744e-01, 1.2680e-02]],\n",
      "\n",
      "        [[6.5042e-02, 1.4287e+00, 1.0846e-01, 3.4970e-02],\n",
      "         [8.3901e-02, 1.5813e-02, 7.1363e-01, 1.7025e-02],\n",
      "         [6.2902e-01, 1.0744e+00, 1.4493e+00, 2.3135e-01],\n",
      "         [3.1544e-01, 1.4416e+00, 3.8314e-02, 7.0265e-02],\n",
      "         [8.6040e-01, 1.0164e+00, 3.9120e-01, 3.5226e-03],\n",
      "         [2.4874e-02, 1.0566e+00, 8.0989e-01, 5.3435e-02]],\n",
      "\n",
      "        [[4.8204e-03, 3.8826e-01, 6.4614e-01, 5.1385e-02],\n",
      "         [2.2587e-01, 1.9928e-01, 8.3169e-02, 8.0206e-02],\n",
      "         [3.6906e-01, 2.1565e-01, 5.0011e-03, 4.5294e-03],\n",
      "         [1.4140e-01, 3.9501e-01, 8.7875e-01, 2.2085e-02],\n",
      "         [5.5053e-01, 1.9008e-01, 2.5775e-01, 2.2376e-01],\n",
      "         [7.7777e-04, 2.0771e-01, 5.4389e-02, 3.3316e-02]],\n",
      "\n",
      "        [[2.5445e-01, 6.2016e-01, 5.8060e-01, 1.9453e-01],\n",
      "         [1.6211e-03, 7.9531e-02, 6.0779e-02, 1.4787e-01],\n",
      "         [1.0868e+00, 3.9536e-01, 1.2673e-02, 5.4029e-01],\n",
      "         [6.5777e-01, 6.2867e-01, 8.0203e-01, 2.6950e-01],\n",
      "         [1.3853e+00, 3.6046e-01, 2.1700e-01, 3.7910e-02],\n",
      "         [1.6574e-01, 3.8458e-01, 3.6618e-02, 2.3543e-01]],\n",
      "\n",
      "        [[3.1123e-01, 1.2335e+00, 4.8344e-02, 2.2247e-02],\n",
      "         [1.2157e+00, 1.6911e-03, 8.7357e-02, 8.5805e-03],\n",
      "         [3.9239e-04, 9.0613e-01, 4.2860e-01, 1.9637e-01],\n",
      "         [6.3139e-02, 1.2455e+00, 1.2494e-01, 5.1632e-02],\n",
      "         [1.3148e-02, 8.5288e-01, 5.8156e-03, 9.4479e-03],\n",
      "         [4.2928e-01, 8.8978e-01, 1.2302e-01, 3.7369e-02]],\n",
      "\n",
      "        [[2.8036e-01, 6.9128e-02, 1.3135e-02, 1.0058e-01],\n",
      "         [2.3092e-04, 6.5059e-01, 1.6066e-01, 1.3962e-01],\n",
      "         [1.1397e+00, 1.0857e-02, 5.7751e-01, 5.3611e-04],\n",
      "         [6.9906e-01, 7.1989e-02, 6.1601e-02, 5.7153e-02],\n",
      "         [1.4449e+00, 5.7457e-03, 3.2952e-02, 3.1752e-01],\n",
      "         [1.8678e-01, 9.1335e-03, 2.0794e-01, 7.4519e-02]],\n",
      "\n",
      "        [[1.8096e-02, 1.2341e+00, 2.8868e-02, 1.4919e-04],\n",
      "         [1.6824e-01, 1.7122e-03, 4.6969e-01, 1.9633e-03],\n",
      "         [4.5238e-01, 9.0662e-01, 1.0909e+00, 9.3758e-02],\n",
      "         [1.9459e-01, 1.2461e+00, 1.3190e-03, 8.1515e-03],\n",
      "         [6.5136e-01, 8.5335e-01, 2.1719e-01, 5.4822e-02],\n",
      "         [1.3840e-03, 8.9027e-01, 5.4837e-01, 3.1777e-03]],\n",
      "\n",
      "        [[1.0446e-01, 1.6225e+00, 9.3947e-01, 9.2704e-01],\n",
      "         [7.5324e-01, 4.1718e-02, 2.0596e-01, 8.2139e-01],\n",
      "         [4.6167e-02, 1.2433e+00, 8.9718e-03, 1.5796e+00],\n",
      "         [2.7563e-04, 1.6362e+00, 1.2163e+00, 1.0835e+00],\n",
      "         [1.2204e-01, 1.1808e+00, 4.5311e-01, 5.1333e-01],\n",
      "         [1.7684e-01, 1.2241e+00, 1.5892e-01, 1.0140e+00]],\n",
      "\n",
      "        [[2.7316e-01, 5.9138e-01, 5.7451e-01, 8.7518e-02],\n",
      "         [1.1392e+00, 9.0302e-02, 5.8821e-02, 1.2416e-01],\n",
      "         [2.3797e-04, 3.7245e-01, 1.3591e-02, 3.4253e-06],\n",
      "         [4.6674e-02, 5.9969e-01, 7.9487e-01, 4.7421e-02],\n",
      "         [2.2470e-02, 3.3860e-01, 2.1329e-01, 2.9397e-01],\n",
      "         [3.8435e-01, 3.6199e-01, 3.5102e-02, 6.3342e-02]]])\n"
     ]
    }
   ],
   "source": [
    "s2 = s1*2\n",
    "print(((a1-b1)**2*s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False,  True,  True,  True],\n",
      "        [ True, False,  True,  True],\n",
      "        [ True,  True, False, False],\n",
      "        [ True,  True, False, False]])\n",
      "torch.Size([4, 4])\n",
      "torch.Size([4, 4])\n",
      "torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "H = torch.randn(4, 4)\n",
    "H= H @ H.T\n",
    "epsilon = 1e-6\n",
    "A_reg = H + epsilon * torch.eye(H.size(0))\n",
    "# H[diag, diag] += damp\n",
    "print(H<0)\n",
    "H = torch.linalg.cholesky(H)\n",
    "print(H.shape)\n",
    "H = torch.cholesky_inverse(H)\n",
    "print(H.shape)\n",
    "H = torch.linalg.cholesky(H, upper=True)\n",
    "print(H.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(H.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 's1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/quant/AQLM-main/notebooks/kmeans.ipynb Cell 41\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B192.168.242.193/home/quant/AQLM-main/notebooks/kmeans.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m s1\n",
      "\u001b[0;31mNameError\u001b[0m: name 's1' is not defined"
     ]
    }
   ],
   "source": [
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "Couldn't reach 'ivanzhouyq/RedPajama-Tiny' on the Hub (ConnectionError)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/home/quant/AQLM-main/notebooks/kmeans.ipynb Cell 43\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B192.168.242.193/home/quant/AQLM-main/notebooks/kmeans.ipynb#X60sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B192.168.242.193/home/quant/AQLM-main/notebooks/kmeans.ipynb#X60sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m os\u001b[39m.\u001b[39menviron[\u001b[39m\"\u001b[39m\u001b[39mHF_ENDPOINT\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhttps://hf-mirror.com\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B192.168.242.193/home/quant/AQLM-main/notebooks/kmeans.ipynb#X60sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m load_dataset(\u001b[39m\"\u001b[39;49m\u001b[39mivanzhouyq/RedPajama-Tiny\u001b[39;49m\u001b[39m\"\u001b[39;49m, split\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/.conda/envs/AWQ/lib/python3.10/site-packages/datasets/load.py:2523\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[1;32m   2518\u001b[0m verification_mode \u001b[39m=\u001b[39m VerificationMode(\n\u001b[1;32m   2519\u001b[0m     (verification_mode \u001b[39mor\u001b[39;00m VerificationMode\u001b[39m.\u001b[39mBASIC_CHECKS) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m save_infos \u001b[39melse\u001b[39;00m VerificationMode\u001b[39m.\u001b[39mALL_CHECKS\n\u001b[1;32m   2520\u001b[0m )\n\u001b[1;32m   2522\u001b[0m \u001b[39m# Create a dataset builder\u001b[39;00m\n\u001b[0;32m-> 2523\u001b[0m builder_instance \u001b[39m=\u001b[39m load_dataset_builder(\n\u001b[1;32m   2524\u001b[0m     path\u001b[39m=\u001b[39;49mpath,\n\u001b[1;32m   2525\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m   2526\u001b[0m     data_dir\u001b[39m=\u001b[39;49mdata_dir,\n\u001b[1;32m   2527\u001b[0m     data_files\u001b[39m=\u001b[39;49mdata_files,\n\u001b[1;32m   2528\u001b[0m     cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m   2529\u001b[0m     features\u001b[39m=\u001b[39;49mfeatures,\n\u001b[1;32m   2530\u001b[0m     download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[1;32m   2531\u001b[0m     download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[1;32m   2532\u001b[0m     revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m   2533\u001b[0m     token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m   2534\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m   2535\u001b[0m     trust_remote_code\u001b[39m=\u001b[39;49mtrust_remote_code,\n\u001b[1;32m   2536\u001b[0m     _require_default_config_name\u001b[39m=\u001b[39;49mname \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   2537\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mconfig_kwargs,\n\u001b[1;32m   2538\u001b[0m )\n\u001b[1;32m   2540\u001b[0m \u001b[39m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[1;32m   2541\u001b[0m \u001b[39mif\u001b[39;00m streaming:\n",
      "File \u001b[0;32m~/.conda/envs/AWQ/lib/python3.10/site-packages/datasets/load.py:2195\u001b[0m, in \u001b[0;36mload_dataset_builder\u001b[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, use_auth_token, storage_options, trust_remote_code, _require_default_config_name, **config_kwargs)\u001b[0m\n\u001b[1;32m   2193\u001b[0m     download_config \u001b[39m=\u001b[39m download_config\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m download_config \u001b[39melse\u001b[39;00m DownloadConfig()\n\u001b[1;32m   2194\u001b[0m     download_config\u001b[39m.\u001b[39mstorage_options\u001b[39m.\u001b[39mupdate(storage_options)\n\u001b[0;32m-> 2195\u001b[0m dataset_module \u001b[39m=\u001b[39m dataset_module_factory(\n\u001b[1;32m   2196\u001b[0m     path,\n\u001b[1;32m   2197\u001b[0m     revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m   2198\u001b[0m     download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[1;32m   2199\u001b[0m     download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[1;32m   2200\u001b[0m     data_dir\u001b[39m=\u001b[39;49mdata_dir,\n\u001b[1;32m   2201\u001b[0m     data_files\u001b[39m=\u001b[39;49mdata_files,\n\u001b[1;32m   2202\u001b[0m     cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m   2203\u001b[0m     trust_remote_code\u001b[39m=\u001b[39;49mtrust_remote_code,\n\u001b[1;32m   2204\u001b[0m     _require_default_config_name\u001b[39m=\u001b[39;49m_require_default_config_name,\n\u001b[1;32m   2205\u001b[0m     _require_custom_configs\u001b[39m=\u001b[39;49m\u001b[39mbool\u001b[39;49m(config_kwargs),\n\u001b[1;32m   2206\u001b[0m )\n\u001b[1;32m   2207\u001b[0m \u001b[39m# Get dataset builder class from the processing script\u001b[39;00m\n\u001b[1;32m   2208\u001b[0m builder_kwargs \u001b[39m=\u001b[39m dataset_module\u001b[39m.\u001b[39mbuilder_kwargs\n",
      "File \u001b[0;32m~/.conda/envs/AWQ/lib/python3.10/site-packages/datasets/load.py:1846\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[0m\n\u001b[1;32m   1841\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e1, \u001b[39mFileNotFoundError\u001b[39;00m):\n\u001b[1;32m   1842\u001b[0m                 \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m   1843\u001b[0m                     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find a dataset script at \u001b[39m\u001b[39m{\u001b[39;00mrelative_to_absolute_path(combined_path)\u001b[39m}\u001b[39;00m\u001b[39m or any data file in the same directory. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1844\u001b[0m                     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m on the Hugging Face Hub either: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(e1)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00me1\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1845\u001b[0m                 ) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1846\u001b[0m             \u001b[39mraise\u001b[39;00m e1 \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1847\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1848\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m   1849\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find a dataset script at \u001b[39m\u001b[39m{\u001b[39;00mrelative_to_absolute_path(combined_path)\u001b[39m}\u001b[39;00m\u001b[39m or any data file in the same directory.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1850\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/AWQ/lib/python3.10/site-packages/datasets/load.py:1780\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# noqa catch any exception of hf_hub and consider that the dataset doesn't exist\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\n\u001b[1;32m   1773\u001b[0m         e,\n\u001b[1;32m   1774\u001b[0m         (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1778\u001b[0m         ),\n\u001b[1;32m   1779\u001b[0m     ):\n\u001b[0;32m-> 1780\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt reach \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m on the Hub (\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(e)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1781\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m404\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(e):\n\u001b[1;32m   1782\u001b[0m         msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDataset \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt exist on the Hub\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mConnectionError\u001b[0m: Couldn't reach 'ivanzhouyq/RedPajama-Tiny' on the Hub (ConnectionError)"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
    "load_dataset(\"ivanzhouyq/RedPajama-Tiny\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.3071)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.randn(10, 3, 4)  # 例如，形状为[2, 3, 4]\n",
    "y = torch.randn(3, 4)\n",
    "# 计算x的整体二范数\n",
    "((x@y.t())**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6681)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((x@y.t())**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3585)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AWQ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
